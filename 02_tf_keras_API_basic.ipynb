{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_tf.keras API basic",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmjayAhn/study_deeplearning/blob/master/02_tf_keras_API_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "bQa8w1K_zbHl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AtG-UbXxCVxc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "17a95194-cf1f-40e3-875e-5da302dc5262"
      },
      "cell_type": "code",
      "source": [
        "!pip list | grep tensorflow"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mesh-tensorflow          0.0.5                \n",
            "tensorflow               1.13.0rc1            \n",
            "tensorflow-estimator     1.13.0rc0            \n",
            "tensorflow-hub           0.2.0                \n",
            "tensorflow-metadata      0.9.0                \n",
            "tensorflow-probability   0.5.0                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yym2C1CS-qAy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Introduction"
      ]
    },
    {
      "metadata": {
        "id": "32P9fB2n-smH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "tensorflow가 2.0부터 tf.keras를 main api로 채택한다고 한다. <br>\n",
        "아직은 1.12버전에서 (여기서 1.12는 1 < 1.12 < 2 를 만족하는 소수를 뜻하는 것이 아니라 열두번째 버전을 의미한다.) tensorflow 고유의 symbolic graph를 이용한 연산 API를 default로 제공하고 있지만, 우리는 발빠르게 version up을 준비 할 필요가 있다. <br> \n",
        "\n",
        "그래야 간지가 나기 때문이다."
      ]
    },
    {
      "metadata": {
        "id": "lqHzxAND4zuq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### example data"
      ]
    },
    {
      "metadata": {
        "id": "FO-T_CZE-u0d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "tf.keras API는 기본적으로 Deep Learning Model을 설계하기 위한 framework이기 때문에 Train Data가 필요하다. <br>\n",
        "\n",
        "모델의 동작과 기능을 테스트 할 수 있는 간단한 데이터를 아래와 같이 준비해준다"
      ]
    },
    {
      "metadata": {
        "id": "MR4BbMzBUN-m",
        "colab_type": "code",
        "outputId": "b400d67c-cbfe-45ab-d7cd-ac42c5151633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "data = np.array([[1, 2, 3, 4, 5], [5, 4, 3, 2, 1]], np.float32)\n",
        "label = np.array([[1], [0]], np.float32)\n",
        "\n",
        "for d, l in zip(data, label):\n",
        "  print(d, l)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 2. 3. 4. 5.] [1.]\n",
            "[5. 4. 3. 2. 1.] [0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sYOluW9jIqhf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### keras.Sequential style"
      ]
    },
    {
      "metadata": {
        "id": "ca20IZ-38K4W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "아래는 tf.keras.Sequential 클래스를 활용하여 FFNN 모델을 설계한 모습이다. <br>\n",
        "여기서 주의해야 할 점은 레이어가 들어가는 부분에는 반드시 tf.keras.layer 만 들어갈 수 있다는 점이다. <br>\n",
        "\n",
        "tf.keras.layers에 정의되어 있는 함수만 사용 할 수 있으니 이에 유의하여 레이어를 설계하면 된다. <br>\n",
        "\n",
        "또한 이 예제에서는 모든 코드를 함수 형태로 작성하였는데,  activation이나 optimizer, loss, metrics 등은 아래와 같이 string type으로 입력이 가능하다. <br>\n",
        "\n",
        "activation='sigmoid' <br>\n",
        "optimizer='SGD' <br>\n",
        "metrics=['accuracy'] <br> \n",
        "metrics=['acc'] <br>\n",
        "\n",
        "하지만 간지와 편의성을 맞바꾸는 변태적인 품위를 유지하기 위해 앞으로도 계속 builtin function을 그대로 사용하도록 하겠다. <br>\n",
        "\n",
        "모름지기 프로그래머라면 이정도 품위는 지켜주는 것이 좋다."
      ]
    },
    {
      "metadata": {
        "id": "SguZQ3NrdcRx",
        "colab_type": "code",
        "outputId": "f307cce1-649e-480b-90d0-3f41eb9a4139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "cell_type": "code",
      "source": [
        "# 모델 생성 방법 1\n",
        "model = tf.keras.Sequential([\n",
        "    # 모든 connection이 모두 꽉 차있는 layer : Dense (그림1)\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.train.GradientDescentOptimizer(1e-2),\n",
        "              loss=tf.keras.losses.binary_crossentropy,\n",
        "              metrics=[tf.keras.metrics.binary_accuracy])\n",
        "\n",
        "model.fit(data, label, epochs=10)\n",
        "result = model.predict_classes(data)\n",
        "print(result)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:642: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 1s 427ms/sample - loss: 3.4695 - binary_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 3ms/sample - loss: 2.7651 - binary_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 2.2039 - binary_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 1.7550 - binary_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 1.4044 - binary_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 3ms/sample - loss: 1.1373 - binary_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 0.9334 - binary_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 0.7750 - binary_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 0.6505 - binary_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 0.5516 - binary_accuracy: 1.0000\n",
            "[[1]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Et8AyTewIw85",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### keras.Sequential style 2"
      ]
    },
    {
      "metadata": {
        "id": "tbdvNm879Uss",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "꼭 Sequential 클래스의 생성자를 이용하지 않더라도 아래와 같이 add() 메서드를 이용하여 레이어를 추가해 나갈 수도 있다. <br>\n",
        "\n",
        "이 역시 반드시 tf.keras.layers만 수용한다"
      ]
    },
    {
      "metadata": {
        "id": "vIwm43o0eThY",
        "colab_type": "code",
        "outputId": "c58f49f5-86b4-4f9c-ea22-e1aea4c44a2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "# 모델 생성 방법 2\n",
        "model = tf.keras.Sequential()\n",
        "# model 을 먼저 선언하고 append 개념으로 넣어주는 방법\n",
        "model.add(tf.keras.layers.Dense(10))\n",
        "model.add(tf.keras.layers.Dense(10))\n",
        "model.add(tf.keras.layers.Dense(10))\n",
        "model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
        "\n",
        "model.compile(optimizer=tf.train.GradientDescentOptimizer(1e-2),\n",
        "              loss=tf.keras.losses.binary_crossentropy,\n",
        "              metrics=[tf.keras.metrics.binary_accuracy])\n",
        "\n",
        "model.fit(data, label, epochs=10)\n",
        "result = model.predict_classes(data)\n",
        "print(result)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 0s 61ms/sample - loss: 3.4569 - binary_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 1.9328 - binary_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 0.7967 - binary_accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 0.2671 - binary_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 0.1575 - binary_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 0.1249 - binary_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 0.1096 - binary_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 0.1004 - binary_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 3ms/sample - loss: 0.0938 - binary_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 3ms/sample - loss: 0.0887 - binary_accuracy: 1.0000\n",
            "[[1]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Il7SLxK_I3tx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### keras.Model style (we will use)"
      ]
    },
    {
      "metadata": {
        "id": "6IILhcwZBwHT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "사실 Sequential은 단순하다. 그래서 간지가 나지 않는다. <br>\n",
        "우리가 이제부터 사용 할 API는 tf.keras.Model이니 이 부분을 유심히 보도록 하자 <br><br>\n",
        "\n",
        "차이점이라고 하면 tf.keras.Input 이라는 코드가 추가된 부분이라는 것과, model을 생성하는 시점, input argument 받는 방식 등이 있다. <br><br>\n",
        "\n",
        "차근차근 살펴보면, 사실 Sequential에 차례로 넣었던 것들은 사실 함수가 아니다. <br>\n",
        "layer.Dense라는 클래스의 생성자를 호출 한 것이며, 이 생성자를 통해 layers.Dense라는 객체를 생성해서 Sequential에 넘기는 방식이다. <br>\n",
        "Dense 객체가 만들어지면 이 객체를 바로 함수처럼 바로 call 할 수 있도록 설계됐는데, 이는 아래 코드를 보면 알 수 있다. <br>\n",
        "여기서 알 수 있는 점 한가지. Sequential에서 list로 저 함수들을 받아서 차례로 아래와 같이 call을 해주는 역할을 해준다는 것을 알 수 있다.<br><br>\n",
        "\n",
        "파이썬을 사용해보지 않은 분들은 조금 생소한 표현 방법일 수 있지만 tf.keras는 이러한 표현 방식을 적극 수용한다. <br>\n",
        "모든 layer 객체는 저렇게 생성된다고 보면 된다. <br> <br>\n",
        "\n",
        "우리가 이 API를 사용 할 필요가 있는 이유는 입출력 interface가 노출되어 있다는 점이다. <br>\n",
        "Sequential을 시용할 경우 입력, 출력 값에 우리가 접근 할 방법이 없다. <br>\n",
        "레이어를 설계하다보면 좀 샛길이 생길수도 있고, 갈림길도 생길 수 있다<br><br>\n",
        "\n",
        "고속도로같은 레이어 설계를 할 때는 Sequential을 이용하는게 편리하지만, 조금이라도 복잡한 모델을 짜는걸 생각한다면 아래의 스타일을 따르는 것이 편리하다.<br><br>\n",
        "\n",
        "마지막으로 Input 부분인데, Sequential에선 볼 수 없는 라인이다. <br>\n",
        "여기다가는 내가 입력할 데이터의 shape을 적어주면 된다. <br> \n",
        "그렇게 Input과 output이 정의되면 tf.keras.Model은 input, output으로 정의된 부분을 받아서 모델 전체를 정의 할 수 있다\n"
      ]
    },
    {
      "metadata": {
        "id": "n8mSGo-DeplP",
        "colab_type": "code",
        "outputId": "7dc8864c-682a-4551-d684-9efc0aa35192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "# 이것은 다른 방법\n",
        "# 큰 차이점 : input output 이 처음것은 명시되어 있지 않음\n",
        "# 이것은 input, output layer 가 있음\n",
        "# middle level 의 api 이 전것들은 high level\n",
        "\n",
        "# input : shape을 넣어주면서 왜 input 을 넣어주어야 하는가?\n",
        "# 이전에 placeholder (shape()) 으로 넣어주었다.\n",
        "# placeholder 를 input 으로 많이 사용했었다. \n",
        "# w(weight)와 const(value) 상수를 내부적으로 정해놓고 갈수가 있음, model 안에서 정의될 수 있는 value 이다.\n",
        "# 사용자가 w 와 const 를 건드릴 수 없다.\n",
        "# 사용자의 data를 초깃값으로 placeholder 에 넣어줄 수 있다.\n",
        "inputs = tf.keras.Input(shape=(5,)) # 옛날의 placeholder 개념이 여기 input 으로 사용되게 된다.\n",
        "x = tf.keras.layers.Dense(10)(inputs) # 두 개의 괄호 : lambda 표현식 Dense(10)이 생성자\n",
        "\n",
        "# def __init__(self)\n",
        "#   이 생성자는 return 이 없어야 한다\n",
        "\n",
        "# def __call__(self)\n",
        "#   리턴 타입이 함수형이다.\n",
        "#   return function \n",
        "\n",
        "x = tf.keras.layers.Dense(10)(x)\n",
        "x = tf.keras.layers.Dense(10)(x)\n",
        "out = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(x)\n",
        "\n",
        "# 모델은 시작과 끝만 알려주면 된다. 연결성은 위에서 정의를 해준다.\n",
        "# 이는 symbolic graphic 형태이기 때문에 가질 수 있는 장점이다.\n",
        "# input 과 output 을 여러개로 넣고 빼려면 () 튜플 형태로 넣어주면된다.\n",
        "model = tf.keras.Model(inputs=inputs, outputs=out)\n",
        "\n",
        "# compile (train 시 lossfounction, optimizer, matrix 등을 추가해서 해석)\n",
        "model.compile(optimizer=tf.train.GradientDescentOptimizer(1e-2),\n",
        "              loss=tf.keras.losses.binary_crossentropy,\n",
        "              metrics=[tf.keras.metrics.binary_accuracy])\n",
        "\n",
        "# train (fit)\n",
        "model.fit(data, label, epochs=10)\n",
        "result = model.predict(data)\n",
        "print(result)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 0s 64ms/sample - loss: 1.6573 - binary_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 0.5634 - binary_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 0.2535 - binary_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 0.2007 - binary_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 0.1667 - binary_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 3ms/sample - loss: 0.1418 - binary_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 0.1229 - binary_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 0.1081 - binary_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 0.0963 - binary_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 2ms/sample - loss: 0.0867 - binary_accuracy: 1.0000\n",
            "[[0.9385344 ]\n",
            " [0.08961135]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4a7geuRQJgaL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### keras.Lambda"
      ]
    },
    {
      "metadata": {
        "id": "TdAoigRTGHFV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "사실 tf.keras API 가 단순연산에 그렇게 직관적인 편은 아니다. <br>\n",
        "5랑 10을 곱하기가 이렇게 힘들다. <br><br>\n",
        "\n",
        "사실 tf.keras.layers에 모든 연산이 다 정의 돼있진 않기 때문에 (딥러닝에 쓸만한 몇가지 연산만 정의돼있다.) 사용자가 직접 tf.keras.layer 클래스를 상속받아서 custom layer를 작성하거나 아래처럼 Labmda 를 이용하여 lambda 표현식으로 layer 형태로 연산을 수행 할 수 있다. <br><br>"
      ]
    },
    {
      "metadata": {
        "id": "BPJimfH5Jfhn",
        "colab_type": "code",
        "outputId": "7e836c93-0439-411a-d6e3-7c6f8a09719b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "input1 = tf.keras.Input(shape=(1,))\n",
        "input2 = tf.keras.Input(shape=(1,))\n",
        "\n",
        "# 기본 연산을 해주기 위해서 Lambda layer 를 활용해주는 것이다.\n",
        "# input1 과 input2 가 x[0], x[1]에 들어가는 것 \n",
        "# 이 연산을 해주기 위해서 Lambda layer 가 들어가는 것\n",
        "out = tf.keras.layers.Lambda(lambda x: x[0] * x[1])([input1, input2])\n",
        "model = tf.keras.Model(inputs=(input1, input2), outputs=out)\n",
        "\n",
        "result = model.predict(([5], [10]))\n",
        "print(result)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[50.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AslF2pF_O6NJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이를 직관적으로 표현하는 방법으로 tensorflow에서는 eager mode를 제공하고 있다."
      ]
    },
    {
      "metadata": {
        "id": "e6ulaqENDmWZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# eagermode 가 실행 되었을 때, 계산 방법\n",
        "const1 = tf.constant(5)\n",
        "const2 = tf.constant(10)\n",
        "result = const1 * const2\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SO9pvUuB4k7r",
        "colab_type": "code",
        "outputId": "d86f32e6-f820-4be5-b314-012db0f648c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# eager mode 가 없을 때는, interprete 하게 계산을 하고 결과를 확인해줄 수 있게끔 해주는 것이다.\n",
        "const1 = tf.constant(5)\n",
        "const2 = tf.constant(10)\n",
        "result = const1 * const2\n",
        "print(result)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  res = sess.run(result)\n",
        "  print(res)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"mul_1:0\", shape=(), dtype=int32)\n",
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MitNROcADIoB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}